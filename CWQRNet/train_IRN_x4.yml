
#### general settings

name: MLRN_DB_x4_DIV2K_AB_009
use_tb_logger: false  # default: true
model: MLRN
distortion: sr
scale: 4
gpu_ids: [0]
#use_KL_Loss: True
use_KL_Loss: False # 7w go!
use_Norm_Layer: True  # 边缘特征
#ab_wavelet: db2 # ['wfml', 'haar', 'db2', 'db3', 'ch22', 'ch33']
ab_wavelet: DCWML # ['haar', 'DCWML', 'db3', 'ch22', 'ch33']


#### datasets

datasets:
  train:
    name: DIV2K
    mode: LQGT
    dataroot_GT: ../train/DIV2K/HR/x4 # path to training HR images
    dataroot_LQ: ../train/DIV2K/LR/x4 # path to training reference LR images, not necessary, if not provided, LR images will be generated in dataloader

    use_shuffle: true
    n_workers: 6  # per GPU
    batch_size: 1  # 16 default
    GT_size: 144
    use_flip: true
    use_rot: true
    color: RGB

#  val:
#    name: val_DIV2K
#    mode: LQGT
#    dataroot_GT: ./validation/DIV2K_val/HR/x4 # path to validation HR images
#    dataroot_LQ: ./validation/DIV2K_val/LR/x4 # path to validation reference LR images, not necessary, if not provided, LR images will be generated in dataloader

  val:
    name: Set5
    mode: LQGT
    dataroot_GT: ../validation/Set5/HR/x4 # path to test HR images
    dataroot_LQ: ../validation/Set5/LR/x4 # path to test reference LR images, not necessary, if not provided, LR images will be generated in dataloader


#### network structures

network_G:
  which_model_G:
      subnet_type: DBNet
  in_nc: 3
  out_nc: 3
  block_num: [4, 4]
  scale: 4
  init: xavier
  window_size: 8

#### path

path:
  pretrain_model_G: ~ # /root/autodl-tmp/experiments/01_IRN_DB_x4_scratch_DIV2K/models/5000_G.pth
  strict_load: true
  resume_state: ~ # /root/autodl-tmp/experiments/01_IRN_DB_x4_scratch_DIV2K/training_state/5000.state


#### training settings: learning rate scheme, loss

train:
  lr_G: !!float 2e-4
  beta1: 0.9
  beta2: 0.999
  niter: 30000
  warmup_iter: -1  # no warm up

  lr_scheme: MultiStepLR
#  lr_steps: [5600, 11200, 16800, 22400, 28000]  # low
  lr_steps: [10000, 15000, 20000, 25000]  # high
#  lr_steps: [10000, 16000, 22000, 28000]  #6
  lr_gamma: 0.5

  pixel_criterion_forw: l2
  pixel_criterion_back: l1
  pixel_criterion_kl: KL

  manual_seed: 10

  val_freq: !!float 5e3

  lambda_fit_forw: 16.
  lambda_rec_back: 1
  lambda_ce_forw: 1
  lambda_rec_kl: 1
  weight_decay_G: !!float 1e-5
  gradient_clipping: 10
  save_pic: true  # save_pic: models-->get_current_visuals;  train--> validation   ban loading and save some big data images



#### logger

logger:
  print_freq: 1
  save_checkpoint_freq: !!float 5e3  # 5e3
